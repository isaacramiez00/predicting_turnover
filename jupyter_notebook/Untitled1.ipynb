{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/isaacramirez/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall-score before leakage: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/isaacramirez/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'last_evaluation_percentage': 0.356528631253801, 'number_project': 0.10858061759057995, 'average_montly_hours': 0.18520320009981456, 'time_spend_company_years': 0.15961759605891074, 'Work_accident': 0.16882908794262802, 'promotion_last_5years': 0.003583117919836418, 'department': 0.0007336500771257512, 'salary': 0.009971471046466746}\n",
      "data-leak-feature: satisfaction_level_percentage\n",
      "recall-score: 0.9\n",
      "{'satisfaction_level_percentage': 0.3302464844332074, 'number_project': 0.13727727374427243, 'average_montly_hours': 0.18222763717703164, 'time_spend_company_years': 0.14935934424912511, 'Work_accident': 0.1749604816952824, 'promotion_last_5years': 0.004115099333427704, 'department': 0.00044332998114101436, 'salary': 0.011372894720404893}\n",
      "data-leak-feature: last_evaluation_percentage\n",
      "recall-score: 0.9\n",
      "{'satisfaction_level_percentage': 0.3542277308636862, 'last_evaluation_percentage': 0.12049212520031938, 'average_montly_hours': 0.17911137432496482, 'time_spend_company_years': 0.13827195845196177, 'Work_accident': 0.1789370591053506, 'promotion_last_5years': 0.005796140441349962, 'department': 0.0003849967199446107, 'salary': 0.014333660884621421}\n",
      "data-leak-feature: number_project\n",
      "recall-score: 0.89\n",
      "{'satisfaction_level_percentage': 0.3452537823546408, 'last_evaluation_percentage': 0.10517425534447526, 'number_project': 0.22997430132055377, 'time_spend_company_years': 0.15316763202919115, 'Work_accident': 0.1437872505216294, 'promotion_last_5years': 0.0029848648578909035, 'department': 0.0009200258150943543, 'salary': 0.010132858010281328}\n",
      "data-leak-feature: average_montly_hours\n",
      "recall-score: 0.9\n",
      "{'satisfaction_level_percentage': 0.37802753333900946, 'last_evaluation_percentage': 0.11278114943770032, 'number_project': 0.14769968387960525, 'average_montly_hours': 0.1603039578685077, 'Work_accident': 0.17885684092762105, 'promotion_last_5years': 0.0021792986114804024, 'department': 0.0003963908989256811, 'salary': 0.010373603839161432}\n",
      "data-leak-feature: time_spend_company_years\n",
      "recall-score: 0.9\n",
      "{'satisfaction_level_percentage': 0.3601159508134239, 'last_evaluation_percentage': 0.11791516605437091, 'number_project': 0.16705557247271322, 'average_montly_hours': 0.14650636300049785, 'time_spend_company_years': 0.18470496257223581, 'promotion_last_5years': 0.0037769482108567973, 'department': 0.000610915575969211, 'salary': 0.011485540349728603}\n",
      "data-leak-feature: Work_accident\n",
      "recall-score: 0.9\n",
      "{'satisfaction_level_percentage': 0.3702480701245499, 'last_evaluation_percentage': 0.12080856636468142, 'number_project': 0.1717902493764458, 'average_montly_hours': 0.13636013105666253, 'time_spend_company_years': 0.17423737408418177, 'Work_accident': 0.004742842156195506, 'department': 0.0011765372588780733, 'salary': 0.013166922376223088}\n",
      "data-leak-feature: promotion_last_5years\n",
      "recall-score: 0.9\n",
      "{'satisfaction_level_percentage': 0.3508561522677533, 'last_evaluation_percentage': 0.14575946213811428, 'number_project': 0.17993284087064182, 'average_montly_hours': 0.14879023329423627, 'time_spend_company_years': 0.1518236506833982, 'Work_accident': 0.0036408747659801323, 'promotion_last_5years': 0.00042749981087860967, 'salary': 0.012853414145789721}\n",
      "data-leak-feature: department\n",
      "recall-score: 0.9\n",
      "{'satisfaction_level_percentage': 0.33936040185185024, 'last_evaluation_percentage': 0.11590105079927668, 'number_project': 0.21074794243895303, 'average_montly_hours': 0.14098333836252566, 'time_spend_company_years': 0.16779796114402254, 'Work_accident': 0.0027628789576030948, 'promotion_last_5years': 0.0011489561849193886, 'department': 0.010584600263263919}\n",
      "data-leak-feature: salary\n",
      "recall-score: 0.9\n",
      "(11991, 8)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import tree\n",
    "import numpy as np\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "'''\n",
    "To whoever looks at this, I apoligize in advance for the terrible code... forgive me\n",
    "'''\n",
    "\n",
    "def plot_histograms():\n",
    "\n",
    "    continous_features = ['satisfaction_level_percentage','last_evaluation_percentage','average_montly_hours']\n",
    "    \n",
    "    for feat in continous_features:\n",
    "        fig, ax = plt.subplots(figsize=(8,5))\n",
    "        ax.hist(x=stayed_df[feat], stacked=True, label='stayed', alpha=0.8)\n",
    "        ax.hist(x=left_df[feat], stacked=True, label='left', alpha=0.8)\n",
    "        ax.set_title(f'{feat}')\n",
    "        ax.set_xlabel(f'{feat}')\n",
    "        ax.set_ylabel('Frequency Count')\n",
    "        plt.legend(loc='best')\n",
    "        fig.tight_layout(pad=2)\n",
    "        plt.savefig(f'{feat}.png')\n",
    "\n",
    "def create_cat_percentage_df():\n",
    "\n",
    "    left_df = turnover[turnover['left']==1]\n",
    "    stayed_df = turnover[turnover['left']==0]\n",
    "\n",
    "    cat_feature = ['number_project', 'time_spend_company_years',\\\n",
    "                   'Work_accident', 'promotion_last_5years', 'department', 'salary']\n",
    "\n",
    "    for cat in cat_feature:\n",
    "        left_df = left_df[cat_feature]\n",
    "        stayed_df = stayed_df[cat_feature]\n",
    "\n",
    "        # initiating the dataframe\n",
    "        current = turnover[cat].value_counts()\n",
    "        current_col = list(current.index)\n",
    "        current_code = turnover[cat].value_counts()\n",
    "        current_code_col = list(current_code.index)\n",
    "\n",
    "        current_dict = {f'{cat}': current_col, 'code': current_code_col} # data for new dataframe\n",
    "        current_df = pd.DataFrame(data=current_dict)\n",
    "\n",
    "        # adding percentage convergance\n",
    "        current_df['left'] = left_df[cat].value_counts()\n",
    "        current_df['stayed'] = stayed_df[cat].value_counts()\n",
    "        current_df['total_count'] = turnover[cat].value_counts()\n",
    "        current_df['left_percentage'] = current_df['left'] / current_df['total_count']\n",
    "        current_df.sort_values(by='left_percentage', axis=0, inplace=True)\n",
    "\n",
    "        plot_side_by_side_percentage_barcharts(current_df)\n",
    "\n",
    "def plot_ROC_curve():\n",
    "    # random forest model w recall score metric\n",
    "\n",
    "    turnover.drop_duplicates(keep='first', inplace=True)\n",
    "    rfc = RandomForestClassifier()\n",
    "    y = turnover.pop('left').values\n",
    "    X = turnover.values\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "    ## data leakage problem\n",
    "    recall_feature_leakage = {}\n",
    "\n",
    "    for idx in range(len(turnover.columns)):\n",
    "        # breakpoint()\n",
    "        features = list(turnover.columns)\n",
    "        data_leakage_feature = features.pop(idx)\n",
    "        X = turnover[features]\n",
    "        rfc.fit(X_train, y_train)\n",
    "        y_pred = rfc.predict(X_test)\n",
    "\n",
    "        feat_dict = {k: v for k, v in zip(features, rfc.feature_importances_)}\n",
    "        print(feat_dict)\n",
    "        print(f'data-leak-feature: {data_leakage_feature}')\n",
    "        \n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        print(f'recall-score: {round(recall,2)}')\n",
    "        recall_feature_leakage[data_leakage_feature] = recall\n",
    "    \n",
    "    print(X.shape)\n",
    "\n",
    "    return recall_feature_leakage\n",
    "\n",
    "        # print(confusion_matrix(y_test, y_pred))\n",
    "        \n",
    "        ## roc curve\n",
    "        # fpr, tpr, thresholds = roc_curve(y_test, y_pred, pos_label=1)\n",
    "        # auc_ = auc(fpr, tpr)\n",
    "\n",
    "        # fig, ax = plt.subplots(figsize=(8,5))\n",
    "\n",
    "        # # roc curve plot\n",
    "        # ax.plot([0, 1], [0, 1], 'k--')\n",
    "        # ax.plot(fpr, tpr, label=f'RFC Recall Score= {round(recall,2)}')\n",
    "        # ax.set_xlabel('False positive rate')\n",
    "        # ax.set_ylabel('True positive rate')\n",
    "        # ax.set_title(f'ROC curve With Out {data_leakage_feature} Feature')\n",
    "        # ax.legend(loc='best')    \n",
    "        # plt.savefig(f'ROC_Curve_Wout_{data_leakage_feature}_feature.png')\n",
    "\n",
    "\n",
    "\n",
    "def plot_side_by_side_percentage_barcharts(df):\n",
    " \n",
    "    column = df.columns[0]\n",
    "    labels = df[column]\n",
    "    data = df['left_percentage']\n",
    "    N = len(df)\n",
    "    fig, ax = plt.subplots(figsize=(8,5))\n",
    "    width = 0.8\n",
    "    tickLocations = np.arange(N)\n",
    "    ax.bar(tickLocations, data, width, linewidth=3.0, align='center')\n",
    "    ax.set_xticks(ticks=tickLocations)\n",
    "    ax.set_xticklabels(labels)\n",
    "    ax.set_xlim(min(tickLocations)-0.6,\\\n",
    "                max(tickLocations)+0.6)\n",
    "    ax.set_xlabel(f'{column}')\n",
    "    ax.set_ylabel('Employee Percent Turnvover')\n",
    "    # ax.set_yticks(np.linspace(0,max(),6))\n",
    "    ax.yaxis.grid(True)\n",
    "    ax.set_title(f'Employer Turnover by {column}')\n",
    "    fig.tight_layout(pad=1)\n",
    "    plt.savefig(f'Employer_Turnover_by_{column}.png')\n",
    "\n",
    "\n",
    "if __name__=='__main__':\n",
    "    # cleaning data \n",
    "    turnover = pd.read_csv(\"../data/turnover.csv\")\n",
    "    salary = turnover['salary'].value_counts()\n",
    "    salary_col = list(salary.index)\n",
    "    turnover[\"salary\"] = turnover[\"salary\"].astype('category').cat.reorder_categories(salary_col).cat.codes\n",
    "    salary_code = turnover.salary.value_counts()\n",
    "    salary_code_col = list(salary_code.index)\n",
    "\n",
    "    salary_dict = {'salary': salary_col, 'code': salary_code_col}\n",
    "    salary_df = pd.DataFrame(data=salary_dict) # use for eda\n",
    "\n",
    "    rename_columns = {'satisfaction_level': 'satisfaction_level_percentage',\\\n",
    "                    'last_evaluation': 'last_evaluation_percentage',\\\n",
    "                    'time_spend_company': 'time_spend_company_years',\\\n",
    "                    'sales': 'department'}\n",
    "    turnover.rename(columns=rename_columns, inplace=True)\n",
    "\n",
    "    department = turnover.department.value_counts()\n",
    "    department_col = list(department.index)\n",
    "    turnover[\"department\"] = turnover[\"department\"].astype('category').cat.reorder_categories(department_col).cat.codes\n",
    "    # department = pd.get_dummies(turnover[\"department\"])\n",
    "    # turnover = turnover.drop([\"department\"], axis=1)\n",
    "    department_code = turnover.department.value_counts()\n",
    "    department_code_col = list(department_code.index)\n",
    "\n",
    "    department_dict = {'department': department_col, 'code': department_code_col}\n",
    "    department_df = pd.DataFrame(data=department_dict) # use for eda\n",
    "\n",
    "    # Data Visualization\n",
    "    '''\n",
    "    create_cat_percentage_df()\n",
    "\n",
    "    ## correlation matrix\n",
    "    fig, ax = plt.subplots(figsize=(9,6))\n",
    "    ax = sns.heatmap(turnover.corr())\n",
    "    plt.savefig('correlation_matrix.png')\n",
    "    plt.tight_layout(pad=4)\n",
    "\n",
    "    ## department eda deepdive\n",
    "    left_df = turnover[turnover['left']==1]\n",
    "    department_df['left'] = left_df['department'].value_counts()\n",
    "\n",
    "    stayed_df = turnover[turnover['left']==0]\n",
    "    department_df['stayed'] = stayed_df['department'].value_counts()\n",
    "\n",
    "    department_df['total_count'] = turnover['department'].value_counts()\n",
    "    department_df['left_percentage'] = department_df['left'] / department_df['total_count']\n",
    "    department_df.sort_values(by='left_percentage', axis=0, inplace=True)\n",
    "\n",
    "    labels = department_df['department']\n",
    "    data = department_df['left_percentage']\n",
    "    N = 10\n",
    "    fig, ax = plt.subplots(figsize=(8,5))\n",
    "    width = 0.8\n",
    "    tickLocations = np.arange(N)\n",
    "    ax.bar(tickLocations, data, width, linewidth=3.0, align='center')\n",
    "    ax.set_xticks(ticks=tickLocations)\n",
    "    ax.set_xticklabels(labels)\n",
    "    ax.set_xlim(min(tickLocations)-0.6,\\\n",
    "                max(tickLocations)+0.6)\n",
    "    ax.set_xlabel('Department')\n",
    "    ax.set_ylabel('Employee Percent Turnvover')\n",
    "    ax.set_yticks(np.linspace(0,0.5,6))\n",
    "    ax.yaxis.grid(True)\n",
    "    ax.set_title('Employer Turnover by Department')\n",
    "    fig.tight_layout(pad=1)\n",
    "    plt.savefig('Employer_Turnover_by_Department.png')\n",
    "\n",
    "    ## Salary eda deepdive\n",
    "    left_df = turnover[turnover['left']==1]\n",
    "    salary_df['left'] = left_df['salary'].value_counts()\n",
    "\n",
    "    stayed_df = turnover[turnover['left']==0]\n",
    "    salary_df['stayed'] = stayed_df['salary'].value_counts()\n",
    "\n",
    "    salary_df['total_count'] = turnover['salary'].value_counts()\n",
    "    salary_df['left_percentage'] = salary_df['left'] / salary_df['total_count']\n",
    "    salary_df.sort_values(by='left_percentage', axis=0, inplace=True)\n",
    "\n",
    "    labels = salary_df['salary']\n",
    "    data = salary_df['left_percentage']\n",
    "    N = 3\n",
    "    fig, ax = plt.subplots(figsize=(8,5))\n",
    "    width = 0.8\n",
    "    tickLocations = np.arange(N)\n",
    "    ax.bar(tickLocations, data, width, linewidth=3.0, align='center')\n",
    "    ax.set_xticks(ticks=tickLocations)\n",
    "    ax.set_xticklabels(labels)\n",
    "    ax.set_xlim(min(tickLocations)-0.6,\\\n",
    "                max(tickLocations)+0.6)\n",
    "    ax.set_xlabel('Salary Ranking')\n",
    "    ax.set_ylabel('Employee Percent Turnvover')\n",
    "    ax.set_yticks(np.linspace(0,0.5,6))\n",
    "    ax.yaxis.grid(True)\n",
    "    ax.set_title('Employer Turnover by Salary Rank')\n",
    "    fig.tight_layout(pad=1)\n",
    "    plt.savefig('Employer_Turnover_by_Salary_rank.png')\n",
    "\n",
    "\n",
    "    ## continous-histograms\n",
    "    plot_histograms()\n",
    "    # plt.show()\n",
    "    '''\n",
    "    # plot_ROC_curve()\n",
    "\n",
    "    # plotting fixing recall score\n",
    "    # fig, ax = plt.subplots(figsize=(8,5))\n",
    "    # ax.bar()\n",
    "\n",
    "    # plt.show()\n",
    "\n",
    "    # recall score before dropping data leakage\n",
    "    # turnover.drop_duplicates(keep='first', inplace=True)\n",
    "    rfc = RandomForestClassifier()\n",
    "    y = turnover.pop('left').values\n",
    "    X = turnover.values\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    rfc.fit(X_train, y_train)\n",
    "    y_pred = rfc.predict(X_test)\n",
    "\n",
    "\n",
    "    # print(f'data-leak-feature: {data_leakage_feature}')\n",
    "    \n",
    "    recall_before_drop = recall_score(y_test, y_pred)\n",
    "    print(f'recall-score before leakage: {round(recall_before_drop,2)}')\n",
    "    \n",
    "\n",
    "    turnover = pd.read_csv(\"../data/turnover.csv\")\n",
    "    salary = turnover['salary'].value_counts()\n",
    "    salary_col = list(salary.index)\n",
    "    turnover[\"salary\"] = turnover[\"salary\"].astype('category').cat.reorder_categories(salary_col).cat.codes\n",
    "    salary_code = turnover.salary.value_counts()\n",
    "    salary_code_col = list(salary_code.index)\n",
    "\n",
    "    salary_dict = {'salary': salary_col, 'code': salary_code_col}\n",
    "    salary_df = pd.DataFrame(data=salary_dict) # use for eda\n",
    "\n",
    "    rename_columns = {'satisfaction_level': 'satisfaction_level_percentage',\\\n",
    "                    'last_evaluation': 'last_evaluation_percentage',\\\n",
    "                    'time_spend_company': 'time_spend_company_years',\\\n",
    "                    'sales': 'department'}\n",
    "    turnover.rename(columns=rename_columns, inplace=True)\n",
    "\n",
    "    department = turnover.department.value_counts()\n",
    "    department_col = list(department.index)\n",
    "    turnover[\"department\"] = turnover[\"department\"].astype('category').cat.reorder_categories(department_col).cat.codes\n",
    "    # after dropping data leakage\n",
    "    turnover.drop_duplicates(keep='first', inplace=True)\n",
    "    # y = turnover.pop('left').values\n",
    "    # X = turnover.values\n",
    "    # X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    # rfc.fit(X_train, y_train)\n",
    "    # y_pred = rfc.predict(X_test)\n",
    "    \n",
    "    # recall_after_drop = recall_score(y_test, y_pred)\n",
    "    # print(f'recall-score after leakage: {round(recall_after_drop,2)}')\n",
    "\n",
    "    # recall_scores_arr = np.array([recall_before_drop, recall_after_drop])\n",
    "\n",
    "    # labels = ['Recall Before', 'Recall After']\n",
    "    # data = recall_scores_arr\n",
    "    # N = len(recall_scores_arr)\n",
    "    # fig, ax = plt.subplots(figsize=(8,5))\n",
    "    # width = 0.8\n",
    "    # tickLocations = np.arange(N)\n",
    "    # ax.bar(tickLocations, data, width, linewidth=3.0, align='center')\n",
    "    # ax.set_xticks(ticks=tickLocations)\n",
    "    # ax.set_xticklabels(labels)\n",
    "    # ax.set_xlim(min(tickLocations)-0.6,\\\n",
    "    #             max(tickLocations)+0.6)\n",
    "    # ax.set_xlabel('Recall Scores')\n",
    "    # ax.set_ylabel('Percentage')\n",
    "    # ax.set_yticks(np.linspace(0,1,6))\n",
    "    # ax.yaxis.grid(True)\n",
    "    # ax.set_title('Recall Scores Before and After Data Leakage Exposed')\n",
    "    # fig.tight_layout(pad=1)\n",
    "    # plt.savefig('Recall_b_a_data_leakage.png')\n",
    "    # plt.show()\n",
    "\n",
    "    ## feature importance barplots\n",
    "    features = list(turnover.columns)\n",
    "    feat_dict = {k: v for k, v in zip(features, rfc.feature_importances_)}\n",
    "    # print(feat_dict)\n",
    "    # breakpoint()\n",
    "    imp_feat_df = pd.DataFrame([feat_dict])\n",
    "    imp_feat_df.sort_values(by=0, axis=1, inplace=True)  \n",
    "    \n",
    "    labels = list(imp_feat_df.columns)\n",
    "    data = imp_feat_df.values\n",
    "    data = data.flatten()\n",
    "    y = np.arange(data.shape[0])\n",
    "\n",
    "    width = 0.8\n",
    "    fig, ax = plt.subplots(figsize=(8,5))\n",
    "    ax.barh(y, data, width, align='center')\n",
    "    ax.set_yticks(y)\n",
    "    ax.set_yticklabels(labels)\n",
    "    ax.xaxis.grid(True)\n",
    "    ax.set_ylabel('Feature Importance')\n",
    "    ax.set_xlabel('Percentage')\n",
    "    ax.set_title('Percentage by Feature Importance')\n",
    "    fig.tight_layout(pad=1)\n",
    "    plt.savefig('perc_by_feat_imp.png')\n",
    "    # plt.show()\n",
    "\n",
    "    recall_feature_leakage = plot_ROC_curve()\n",
    "    recall_feature_df = pd.DataFrame([recall_feature_leakage])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>satisfaction_level_percentage</th>\n",
       "      <th>last_evaluation_percentage</th>\n",
       "      <th>number_project</th>\n",
       "      <th>average_montly_hours</th>\n",
       "      <th>time_spend_company_years</th>\n",
       "      <th>Work_accident</th>\n",
       "      <th>promotion_last_5years</th>\n",
       "      <th>department</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.897756</td>\n",
       "      <td>0.897756</td>\n",
       "      <td>0.890274</td>\n",
       "      <td>0.895262</td>\n",
       "      <td>0.900249</td>\n",
       "      <td>0.895262</td>\n",
       "      <td>0.900249</td>\n",
       "      <td>0.900249</td>\n",
       "      <td>0.897756</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   satisfaction_level_percentage  last_evaluation_percentage  number_project  \\\n",
       "0                       0.897756                    0.897756        0.890274   \n",
       "\n",
       "   average_montly_hours  time_spend_company_years  Work_accident  \\\n",
       "0              0.895262                  0.900249       0.895262   \n",
       "\n",
       "   promotion_last_5years  department    salary  \n",
       "0               0.900249    0.900249  0.897756  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_feature_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
